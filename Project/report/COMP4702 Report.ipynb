{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08aa1125-a7f9-4096-96d8-b848fd86d153",
   "metadata": {},
   "source": [
    "COMP4702 Report\n",
    "================\n",
    "\n",
    "Student: Hugo Burton\n",
    "\n",
    "Date Due: Friday $24^{\\text{th}}$ May 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a24d3c-04a2-4d49-b800-fbd93b73c621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\burto\\Documents\\University (2021-2024)\\2024 Semester 1\\COMP4702\\COMP4702\\Project\\report\n",
      "Log level found LOG_LEVEL=DEBUG\n",
      "\n",
      "\u001b[92mWelcome to the Machine Learning Project\n",
      "\u001b[0m\u001b[96mTorch version:  2.2.2+cpu\n",
      "\u001b[0m\u001b[33mCUDA is not available\n",
      "\u001b[0m--------------------------------------------------\n",
      "\u001b[96mPython version: \u001b[0m\u001b[96m3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]\n",
      "\u001b[0m\u001b[96mNumpy version: \u001b[0m\u001b[96m1.26.4\n",
      "\u001b[0m\u001b[96mSeaborn version: \u001b[0m\u001b[96m0.13.2\n",
      "\u001b[0m--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "from welcome import welcome, available_items\n",
    "from check_log_level import set_log_level\n",
    "\n",
    "set_log_level()\n",
    "welcome()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c10bd-44a3-4765-8de8-e6cf4b27ad83",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Introduction to the dataaset\n",
    "\n",
    "This report is an investigation into the quantitative traits of fruit flies, known scientifically as the species _Drosophila aldrichi_ and _D. buzzatii_. The data, collected in 1994 captures a range of traits of $n = 1731$ flies located on the East coast of Australia. The attached report on the dataset aims to contribute to understanding the factors driving latitudinal variation in size-related traits in the two species, considering both genetic adaptation and phenotypic plasticity in response to environmental conditions.\n",
    "\n",
    "Fruit flies are a pest to many kinds of agriculture. Adult female flies lay their eggs within fruit and vegetable crops leading to their larvae hatching inside. These larvae then proceed to each the fruit from the inside out, causing rotting and thus destroying the crop. (Department of Agriculture, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652b9dcf-3786-4434-9893-d5c04206449c",
   "metadata": {},
   "source": [
    "## Preliminary Observations of the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538cf7a8-800f-40b9-99b9-da2ed520df33",
   "metadata": {},
   "source": [
    "Prior to determining an objective for this report, the dataset was analysed from a purely morphological perspective.\n",
    "\n",
    "### Thorax and Wing Traits Dataset\n",
    "\n",
    "A correlation plot of the `Thorax & wing traits` dataset is shown below. Evidently the columns species, population, temperature and sex all show a small magnitude of correlation with columns Thorax length through to wing_loading. \n",
    "\n",
    "Longitude and lattitude do show some correlation (other than with each other) - this could be interesting to investigate, though may not produce the best results from a classifier with this data alone.\n",
    "\n",
    "The columns `Thorax_length` through to `wing_loading` show a highly positive correlation as seen in the bottom-right of the matrix, indicating these variables are very tightly related to each other. For example, we could say a fly with a higher than average Thorax length also very likely has a higher then average wing loading.\n",
    "\n",
    "We note some columns as having no correlation with any other columns, namely `year_start` and `year_end`. Looking at the raw data, we see these are constant for all rows. In any analysis it would be a good decision to strip these from the model as they don't provide any additional information for classification purposes. Additionally, it was observed that there exist only distinct `Latitude` and `Longitudes` which are unique for each population. To make the classification fair, it would also make sense to remove these prior to training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded27d65-a7a1-4e93-95fb-a595e31ad602",
   "metadata": {},
   "source": [
    "##### Thorax Correlation matrix\n",
    "\n",
    "<img src=\"..\\plots\\Thorax_corr_matrix.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0b030e-0dac-4d02-bb61-60bf2b9e85b3",
   "metadata": {},
   "source": [
    "The Wing Traits and Asymmetry dataset does show correlation between each of the wing asymmetry traits, however, it shows little to no correlation between wing asymmetry and species and population. Meaning it is potentially not a good candidate dataset for making predictions about the fly's species and population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79481be-6245-4b8d-902d-f12bf88c0dcb",
   "metadata": {},
   "source": [
    "\n",
    "#### Wing Traits and Asymmetry Correlation Matrix\n",
    "\n",
    "<img src=\"..\\plots\\Wing_asymmetry_corr_matrix.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a6b0ac-b334-4d6a-a0cb-192e339c2f85",
   "metadata": {},
   "source": [
    "The `Wing Asymmetry`  dataset (which has different asymmetry traits from the previous dataset) does show signs of correlation between wing attributes and species & population, though this isn't as strong as the first dataset. It may, however, be a good candidate for determining temperature if that were of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c303336a-113f-4b4c-9fa1-e4331dc5cb0b",
   "metadata": {},
   "source": [
    "#### Wing Asymmetry Correlation Matrix\n",
    "\n",
    "<img src=\"..\\plots\\Wing_traits_corr_matrix.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b87514-fc45-4171-b84d-b65024e752c1",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "While the report attached to these datasets (not this report) does provide explanation of what it is investigating, it does not provide detail on the reasoning behind doing so, other than simply to contribute to knowledge. This report will attempt to develop models which can classify both the **Species** and **Population** of fruit flies given the remaining variables collected. <!--While not covered in the attached report, knowing which species and population a fruit fly in its natural habitat belongs to may be helpful understanding its behaviour-->\n",
    "\n",
    "Secondly, this report will attempt to perform feature selection by first ranking the input variables in descending order of importance. The top important variables will then be sliced from the dataset and used in a second round of classification for each model. Finally, comparisons can then be made between the models trained with all attributes, and models trained with the supposedly redundant attributes removed.\n",
    "\n",
    "Finally, the report will determine a classifier which performs the best for the above object and discuss reasoning for any findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff1be0-1c7c-498f-8a25-80eecc6a41ab",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "The objective defined above is related to classification of the Loeschcke dataset, meaning only classification models will be used. In this report, the following classifiers are:\n",
    "- $k$-NN\n",
    "- Decision Tree\n",
    "- Neural Network\n",
    "\n",
    "\n",
    "Where possible each model will be tested equally on the dataset. Note that in the case of a neural network, a single network can output multiple variables. However, this is not possible with $k$-NN or a decision tree, hence multiple classifiers will be instantiated and combined in order to make these predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc270e5b-989a-40b0-a917-4ca7ff0d0c60",
   "metadata": {},
   "source": [
    "# Hardware\n",
    "\n",
    "The models were trained on the following hardware\n",
    "\n",
    "- Intel&reg; Core&trade; i7 12700K @ 5.0 GHz (8 P-cores, 4 E-cores)\n",
    "- 32GB DDR5 @ 5200 MT/s\n",
    "- Samsung 990 Pro 1TB\n",
    "- Asus ROG STRIX GeForce RTX 3080-Ti OC @ 1940 MHz with 12GB GDDR6X @ 9630MHz\n",
    "- Windows 11 Pro\n",
    "\n",
    "CUDA compute was used to train the neural network model in a conda enviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d3aec-709a-4f1d-ba67-851814dbc1ff",
   "metadata": {},
   "source": [
    "## $k$-NN\n",
    "\n",
    "### Model Setup\n",
    "\n",
    "As two output variables are being predicted, two separate $k$-NN classifiers were constructed, each with equal parameter setups (e.g. train set, test set, cross validation method, etc).\n",
    "\n",
    "### Selection of $k$ - Cross Validation\n",
    "\n",
    "Cross validation was performed for each of the two $k$-NN classifiers (one for each output variable). A grid search over a wide range of $k$ values was performed in order to find the optimal value of $k$. To start, a $30\\%$ test set was put aside and kept independent from cross validation. On the remaining $70\\%$, each $k$ from $1$ through $100$ was trained on a randomly selected $\\frac{4}{5}$ of the train set and validated on the remaining $\\frac{1}{5}$. For each $k$, a new slicing into $5$ buckets was performed. The validation allowed us to obtain an accuracy value for each $k$ in the tested range. Once found, a final classifier was trained on a separate test set (not used in cross validation) to obtain the final results. A plot showing the accuracies for the output variable `Species` (from cross validation) of each $k$ is below:\n",
    "\n",
    "<img src=\"..\\plots\\Thorax_knn_accuracies_Species.png\" width=\"700\">\n",
    "\n",
    "The optimal value of $k$ found was $k = 9$. We observe the accuracy plot, though on a fine scale is not a smooth function. Partially this is due to the dataset being only $n = 1731$ rows which when sliced up into discrete bins used for training reduces the size of each effective training set significantly. Therefore, a small change in $k$ can result in a big change in accuracy due to being \"lucky\" or \"unlucky\" in classification being far more likely. Nonetheless, this does show a clear maximum on the lower end of the x-axis.\n",
    "\n",
    "A plot showing the accuracies for the output variable `Population` is shown below. Note the same range of $k$ was tested.\n",
    "\n",
    "<img src=\"..\\plots\\Thorax_knn_accuracies_Population.png\" width=\"700\">\n",
    "\n",
    "We see from this graph that the optimal value of $k$ was much higher. This indicates population classes are likely more clustered than species. The reasoning behind this being that classes which are more clustered are less likely to decrease in performance with higher $k$ values due to having a majority of that class within a given region in hyperspace. Compared with if the classes are more overlapping or have scattered clusters, a change in $k$, even by $\\Delta k = 1$ could significantly change the accuracy score, and we see this evident in the `Species` classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13926f68-c1b6-4392-85e9-f33b65c51f88",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "The decision tree model had a similar setup to $k$-NN, however without cross validation being used. Due to the small number of features ($14$), the only hyperparameter of the max tree height was chosen at $h_{\\text{max}} = 10$. Instead, the decision tree was utilised for determining the importance of variables or predictors in the dataset. This was done independently for each of the two output variables.\n",
    "\n",
    "Hence when training both the $k$-NN and neural network models, the decision tree was trained on the same data first, not for it's performance, but instead to obtain a ranking of predictor variables. This was then used in order to determine which decision boundary plots to show, given that plotting all of them would be infeasible and difficult to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52a48d-4e25-45bc-abc3-8fa4b108c55d",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8740d70c-6d00-4cc3-a432-f7e68121c5dd",
   "metadata": {},
   "source": [
    "# Ranking of Predictor Variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0919b-7aa5-41e2-9553-ff9ee18b896f",
   "metadata": {},
   "source": [
    "# Decision Boundaries\n",
    "\n",
    "During training of each classifier a total of $14$ predictor variables were fed as inputs for training. While this is by no means a high number of input variables, it would be impractical to plot every pairwise combination of the features as a decision boundary as there would simply be too many plots to show and analyse. We note that decision boundary plots can only really be shown in 2 dimensions (at least for now or without AR!). Instead, using the technique described in the **Ranking of Predictor Variables** section, only the top $\\delta = 5$ variables were considered for their decision boundary. We are interested in the top ranking predictor variables because they are the ones most likely to show a manifold like structure of the data.\n",
    "\n",
    "When plotting pairs of variables, the remaining features are held constant at their respective mean. This does have limitations in that some plots may misrepresent the boundaries, particularly if the size of each class isn't equal, however, it allows us to visualise the model in an easy to understand way.\n",
    "\n",
    "I would argue holding the non-plotted variables at their mean is superior to ploting e.g. PCA because the former method does not cause loss of interpretability of the data. From the plots below we can clearly see the regions of the classes learned by the model with respect to specific variables. Using a dimensionality reduction technique does not make sense here given the already small number of features.\n",
    "\n",
    "In the case of hundreds or thousands of input variables where many of them turn to be important, then PCA could be considered usedful, however, it was not used in this report for the reasons specified above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b023d5aa-4928-4ac7-8135-879be159c0d5",
   "metadata": {},
   "source": [
    "## Decision Boundaries of Species\n",
    "\n",
    "Firstly, we will consider only the decision boundaries of the `Species` output variable.\n",
    "\n",
    "### $k$-NN\n",
    "\n",
    "<img src=\"..\\plots\\knn_Thorax_decision_boundaries_Species.png\" width=\"700\">\n",
    "\n",
    "It is evident from the plot above that `Thorax Length` and `Wing Loading` explain the classes the best. Almost amazingly, we see the plot of the combination of these variables (top-right) as showing almost no wrong predictions.\n",
    "\n",
    "The four plots closest to the bottom show that `w_2` and `Temperature` are not able to predict species very well at all. They only appear at the top of the predictor variables ranking because there are simply no other variables (other than `Thorax_length` and `Wing loading`) which are comparable.\n",
    "\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "<img src=\"..\\plots\\dt_Thorax_decision_boundaries_Species.png\" width=\"700\">\n",
    "\n",
    "The decision tree did not perform as well as $k$-NN, achiving only ___% compared with ___% test accuracy for $k$-NN. The decision tree plot above highlights this finding. Observe (at least for the top predictors) the data is highly correlated - something which a decision tree does not perform well at due to it's lack of ability to draw decision boundaries that are not orthogonal to the axes. \n",
    "\n",
    "We can see in `Wing loading` vs `w2`, the `D._aldrichi` species is almost clustered in the middle of the `D._buzzatii` species. The decision tree did create a small red area in the top in an attempt to capture this, however, it is evident the border is not optimal when compared with the other classifiers.\n",
    "\n",
    "We note the decision tree really does not perform well with the top-two classsifiers `Thorax length` and `wing loading` due to the scattered nature of the classes. This is very different from the $k$-NN classifier where these two predictors were the most critical to enabling the model to perform well.\n",
    "\n",
    "\n",
    "### Neural Network\n",
    "\n",
    "\n",
    "<img src=\"..\\plots\\nn_Thorax_decision_boundaries_Species.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6690599-298a-451e-b735-4747b8a0c53f",
   "metadata": {},
   "source": [
    "\n",
    "## Decision Boundaries of Population\n",
    "\n",
    "Secondly, we will consider only the decision boundaries of the `Population` output variable.\n",
    "\n",
    "### $k$-NN\n",
    "\n",
    "<img src=\"..\\plots\\knn_Thorax_decision_boundaries_Population.png\" width=\"700\">\n",
    "\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "\n",
    "Highly correlated data - not great for decision tree.\n",
    "\n",
    "\n",
    "<img src=\"..\\plots\\dt_Thorax_decision_boundaries_Population.png\" width=\"700\">\n",
    "\n",
    "### Neural Network\n",
    "\n",
    "\n",
    "<img src=\"..\\plots\\nn_Thorax_decision_boundaries_Population.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fe01da-34b2-4f3a-b54e-ba67d0e3bcc8",
   "metadata": {},
   "source": [
    "## Certainty of Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d74107-73fc-4a4c-9b01-1c52bc56e09e",
   "metadata": {},
   "source": [
    "# Ranking of Classifier Models\n",
    "\n",
    "The best classifications occur when the certainty is high and the prediction of class is correct. One sample from the\n",
    "test set was chosen from each classifier for each true class which had maximum certainty and the prediction was\n",
    "correct. The results are outlined below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0331049-44fc-4806-a49d-7535c5a1743d",
   "metadata": {},
   "source": [
    "# Worst Errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dbb187-dddd-47bd-b29b-9efea51f2397",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8077fe-5dad-4768-94bc-e070d78f1d83",
   "metadata": {},
   "source": [
    "# References (yet to compile)\n",
    "\n",
    "1. https://www.agriculture.gov.au/biosecurity-trade/pests-diseases-weeds/fruit-flies-australia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e6488-b47f-4e93-91f6-251084444740",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
